{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8eba714-2eca-4154-9c54-ed8f2359b933",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7e6cd9-9e83-4eea-828f-c9358f0dc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f847252-5a64-420e-a1bc-422165e170c0",
   "metadata": {},
   "source": [
    "## Simple Website Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfcecf2-258c-4062-b0d4-52cf16d42505",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "640bf14b-6d6e-42ea-8c9a-f4e6cde8af8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage Title:\n",
      "Google News\n",
      "Webpage Contents:\n",
      "News\n",
      "Google News\n",
      "Advanced search\n",
      "Help\n",
      "Help\n",
      "Privacy\n",
      "Terms\n",
      "About Google\n",
      "Get the Android app\n",
      "Get the iOS app\n",
      "Send feedback\n",
      "Settings\n",
      "Settings\n",
      "Language & region\n",
      "English (United States)\n",
      "Sign in\n",
      "Home\n",
      "For you\n",
      "Following\n",
      "U.S.\n",
      "World\n",
      "Local\n",
      "Business\n",
      "Technology\n",
      "Entertainment\n",
      "Sports\n",
      "Science\n",
      "Health\n",
      "More\n",
      "News\n",
      "Google News\n",
      "Your\n",
      "briefing\n",
      "Today\n",
      "38°\n",
      "28°\n",
      "Thu\n",
      "37°\n",
      "28°\n",
      "Fri\n",
      "37°\n",
      "27°\n",
      "Sat\n",
      "37°\n",
      "28°\n",
      "Tehran\n",
      "36°C\n",
      "Google Weather\n",
      "Top stories\n",
      "The Guardian\n",
      "More\n",
      "Tsunami warning live updates: Hawaii prepares for first waves; Russia declares emergency after flooding in Kuril Islands\n",
      "57 minutes ago\n",
      "By Jane Clinton, Nick Visser & Kate Lamb\n",
      "Hawaii News Now\n",
      "More\n",
      "LIVE: Tsunami warning issued for Hawaii after M8.8 earthquake off Russia\n",
      "7 hours ago\n",
      "FOX Weather\n",
      "More\n",
      "Tsunami waves begin to hit Hawaii after massive 8.8 quake strikes off Russia\n",
      "6 hours ago\n",
      "By Scott Sistek\n",
      "Fox News\n",
      "More\n",
      "Tsunami waves arrive on Japan's coast after earthquake in Russia, triggering tsunami alerts for US West Coast\n",
      "4 hours ago\n",
      "By Landon Mion\n",
      "Full Coverage\n",
      "ABC News\n",
      "More\n",
      "NYC Mayor Eric Adams shares Midtown shooting surveillance footage details, calls for gun reform\n",
      "6 hours ago\n",
      "By Doc Louallen\n",
      "BBC\n",
      "More\n",
      "Two hours of terror in a New York skyscraper\n",
      "9 hours ago\n",
      "By Madeline Halpert\n",
      "New York Post\n",
      "More\n",
      "NYers mourn fallen hero Didarul Islam in NYC shooting — but don’t count Zohran Mamdani among them\n",
      "1 hour ago\n",
      "Opinion\n",
      "CNN\n",
      "More\n",
      "Inside 345 Park Avenue when a mass killer arrived\n",
      "8 hours ago\n",
      "By Mark Morales, Jessie Yeung & Rachel Clarke\n",
      "Full Coverage\n",
      "AP News\n",
      "More\n",
      "Senate confirms Trump lawyer Emil Bove for appeals court amid whistleblower claims\n",
      "4 hours ago\n",
      "By Mary Clare Jalonick & Eric Tucker\n",
      "Full Coverage\n",
      "CBS News\n",
      "More\n",
      "Senate confirms Susan Monarez as CDC director. Here's what she's said about vaccines, fluoride and more.\n",
      "6 hours ago\n",
      "By Sara Moniuszko\n",
      "Full Coverage\n",
      "Local news\n",
      "Picks for you\n",
      "Sign in for personalized stories in your briefing & news feed\n",
      "Sign in\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the scraper\n",
    "test = Website(\"https://news.google.com\")\n",
    "print(test.get_contents())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e731c65d-d8f9-45eb-a71f-8a0477326d1d",
   "metadata": {},
   "source": [
    "## STEP 1 : Getting relevent link from a webpage\n",
    "Calling the LLM to decide if a webpage is relavant for creating a brouchure or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050acafe-d84b-4791-b2d1-accf960404cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up user and system prompt for finding relevent links using an LLM.\n",
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON and nothing more, skip if it's not a link and you don't need provide additional information, respond just JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "\n",
    "# Calling local LLaMA using openai library\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = MODEL,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "        ]\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7110c773-3222-4f0b-8f3d-5f009aff5bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'links': [{'type': 'company page', 'url': 'https://huggingface.co'}, {'type': 'about page', 'url': 'https://huggingface.co/'}, {'type': 'model links', 'url': 'https://huggingface.co/models/'}, {'type': 'dataset links', 'url': 'https://huggingface.co/datasets/'}, {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'}, {'type': 'join/discord link', 'url': 'https://huggingface.co/join/discord'}, {'type': 'github link', 'url': 'https://github.com/huggingface'}, {'type': 'twitter link', 'url': 'https://twitter.com/huggingface'}, {'type': 'linkedin company page', 'url': 'https://www.linkedin.com/company/huggingface/'}]}\n"
     ]
    }
   ],
   "source": [
    "# Testing get_links\n",
    "test_get_links = get_links(\"https://huggingface.co\")\n",
    "print(test_get_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9788af-ef75-49aa-9996-379fbdaa24d0",
   "metadata": {},
   "source": [
    "## STEP 2 : Creating the Brouchure\n",
    "Calling the LLM again, this time for making the Brouchure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7297d780-5209-4c13-91c0-ba01ea7f5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    # I'm removing facebook and youtube page for technical reasons, if you want to keep them you can delete 2 next line.\n",
    "    links['links'] = [link for link in links['links'] if 'facebook' not in link['type'].lower()]\n",
    "    links['links'] = [link for link in links['links'] if 'youtube' not in link['type'].lower()]\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result\n",
    "\n",
    "# Setting up user and system prompt so we can make a brouchure out of some candidate links.\n",
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt\n",
    "\n",
    "# As the name says this function will create the brouchure, i just wanted to add some comment :)\n",
    "def create_brochure(company_name, url):\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78effc6f-427d-48c7-abbd-78f393120da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': [{'type': 'about page', 'url': 'https://realpython.com/about/'}, {'type': 'mission', 'url': 'https://realpython.com/mission/'}, {'type': 'teams', 'url': 'https://realpython.com/team/'}, {'type': 'newsletter', 'url': 'https://realpython.com/newsletter/'}, {'type': 'media-kit', 'url': 'https://realpython.com/media-kit/'}, {'type': 'sponsorships', 'url': 'https://realpython.com/sponsorships/'}, {'type': 'contact', 'url': 'https://realpython.com/contact/'}]}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Real Python Brochure\n",
       "\n",
       "Real Python is a community-driven platform dedicated to the advancement of Python programming and software development.\n",
       "\n",
       "## Our Mission\n",
       "\n",
       "At Real Python, our mission is to provide high-quality tutorials, resources, and support to learners of all levels. We aim to bridge the gap between beginners and experienced developers by offering guided learning paths, interactive quizzes, and personalized code assistance.\n",
       "\n",
       "## Values\n",
       "\n",
       "*   Community: We believe in building a vibrant community of Pythonistas who can learn from each other, share knowledge, and collaborate on projects.\n",
       "*   Quality: We are committed to delivering the highest-quality content that is accurate, informative, and engaging.\n",
       "*   Accessibility: We strive to make programming skills accessible to everyone, regardless of background or experience.\n",
       "\n",
       "## Customer and Learner Experience\n",
       "\n",
       "Our customers are learners who want to master Python and its ecosystem. They receive:\n",
       "\n",
       "*   In-depth tutorials and video courses\n",
       "*   Guided learning paths for accelerated learning\n",
       "*   Interactive quizzes to evaluate progress\n",
       "    Our commitment is to support our customers throughout their learning journey.\n",
       "\n",
       "## Careers and Jobs\n",
       "\n",
       "Real Python offers various career opportunities for professionals who share our passion for programming and community development. We are dedicated to nurturing:\n",
       "\n",
       "*   Talented individuals who can help us grow and improve\n",
       "*   Employers who can find skilled Python developers on our job board"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And the result ...\n",
    "create_brochure(\"Real Python\", \"https://realpython.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
